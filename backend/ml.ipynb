{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "from datasets import Audio\n",
    "from transformers import pipeline, AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "\n",
    "\n",
    "token_path = Path('token.txt')\n",
    "token = token_path.read_text().strip()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model_id = \"openai/whisper-large-v2\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True,\n",
    "    attn_implementation=\"sdpa\",\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "model.safetensors: 100%|██████████| 6.17G/6.17G [01:31<00:00, 67.3MB/s]\n",
      "generation_config.json: 100%|██████████| 4.26k/4.26k [00:00<00:00, 5.02MB/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51865, bias=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "preprocessor_config.json: 100%|██████████| 185k/185k [00:00<00:00, 8.87MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 805/805 [00:00<00:00, 8.57MB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 27.8MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.48M/2.48M [00:00<00:00, 12.9MB/s]\n",
      "merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 52.4MB/s]\n",
      "normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 50.8MB/s]\n",
      "added_tokens.json: 100%|██████████| 34.6k/34.6k [00:00<00:00, 99.5MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 2.08k/2.08k [00:00<00:00, 21.6MB/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "asr = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        max_new_tokens=128,\n",
    "        chunk_length_s=15,\n",
    "        batch_size=4,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "audio_path = \"/Users/amansingh/Documents/ssr_audio_dataset/audio/6412ba078a3197d8284889fa.wav\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "waveform, _ = librosa.load(audio_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(waveform)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.1837007e-03 2.5585922e-03 2.2247941e-03 ... 3.7024587e-05 5.7741247e-05\n",
      " 0.0000000e+00]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "audio_dict = {\n",
    "        'array': waveform,\n",
    "        'path': audio_path,\n",
    "        'sampling_rate': 16000\n",
    "    }\n",
    ""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "audio_dict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'array': array([2.1837007e-03, 2.5585922e-03, 2.2247941e-03, ..., 3.7024587e-05,\n",
       "        5.7741247e-05, 0.0000000e+00], dtype=float32),\n",
       " 'path': '/Users/amansingh/Documents/ssr_audio_dataset/audio/6412ba078a3197d8284889fa.wav',\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from datasets import Dataset\n",
    "audio_dataset = Dataset.from_dict({\"audio\": [audio_path]}).cast_column(\"audio\", Audio(sampling_rate=16000))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "audio_dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "audio_dataset[0][\"audio\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'path': '/Users/amansingh/Documents/ssr_audio_dataset/audio/6412ba078a3197d8284889fa.wav',\n",
       " 'array': array([ 2.31933594e-03,  2.38037109e-03,  2.31933594e-03, ...,\n",
       "        -3.05175781e-05,  0.00000000e+00,  6.10351562e-05]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "asr(audio_dataset[0][\"audio\"])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m asr(audio_dataset[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39maudio\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py:357\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=293'>294</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=294'>295</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=295'>296</a>\u001b[0m     inputs: Union[np\u001b[39m.\u001b[39mndarray, \u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=296'>297</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=297'>298</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=298'>299</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=299'>300</a>\u001b[0m \u001b[39m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=300'>301</a>\u001b[0m \u001b[39m    documentation for more information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=354'>355</a>\u001b[0m \u001b[39m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=355'>356</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=356'>357</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1132\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1129'>1130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1130'>1131</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1131'>1132</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1132'>1133</a>\u001b[0m         \u001b[39miter\u001b[39;49m(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1133'>1134</a>\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_iterator(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1134'>1135</a>\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1135'>1136</a>\u001b[0m             )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1136'>1137</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1137'>1138</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1138'>1139</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1139'>1140</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=120'>121</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=122'>123</a>\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=123'>124</a>\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=124'>125</a>\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=125'>126</a>\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=262'>263</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=264'>265</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=265'>266</a>\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=266'>267</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py?line=267'>268</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1043'>1044</a>\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1044'>1045</a>\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1045'>1046</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1046'>1047</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1047'>1048</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py:569\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline._forward\u001b[0;34m(self, model_inputs, return_timestamps, generate_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=565'>566</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=566'>567</a>\u001b[0m     generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m encoder(inputs, attention_mask\u001b[39m=\u001b[39mattention_mask)\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=568'>569</a>\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=569'>570</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=570'>571</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=571'>572</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=572'>573</a>\u001b[0m \u001b[39mif\u001b[39;00m return_timestamps \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mword\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseq2seq_whisper\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py?line=573'>574</a>\u001b[0m     out \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m\"\u001b[39m: tokens[\u001b[39m\"\u001b[39m\u001b[39msequences\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mtoken_timestamps\u001b[39m\u001b[39m\"\u001b[39m: tokens[\u001b[39m\"\u001b[39m\u001b[39mtoken_timestamps\u001b[39m\u001b[39m\"\u001b[39m]}\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:2254\u001b[0m, in \u001b[0;36mWhisperForConditionalGeneration.generate\u001b[0;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, num_segment_frames, return_token_timestamps, return_segments, attention_mask, time_precision, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2251'>2252</a>\u001b[0m \u001b[39m# 5. If we're in shortform mode, simple generate the whole input at once and return the output\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2252'>2253</a>\u001b[0m \u001b[39mif\u001b[39;00m is_shortform:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2253'>2254</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2254'>2255</a>\u001b[0m         input_features,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2255'>2256</a>\u001b[0m         generation_config,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2256'>2257</a>\u001b[0m         logits_processor,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2257'>2258</a>\u001b[0m         stopping_criteria,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2258'>2259</a>\u001b[0m         prefix_allowed_tokens_fn,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2259'>2260</a>\u001b[0m         synced_gpus,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2260'>2261</a>\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2261'>2262</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2262'>2263</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2264'>2265</a>\u001b[0m     \u001b[39mif\u001b[39;00m return_token_timestamps \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(generation_config, \u001b[39m\"\u001b[39m\u001b[39malignment_heads\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=2265'>2266</a>\u001b[0m         num_frames \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(generation_config, \u001b[39m\"\u001b[39m\u001b[39mnum_frames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=111'>112</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=113'>114</a>\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=114'>115</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py:1718\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1700'>1701</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1701'>1702</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1702'>1703</a>\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1713'>1714</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1714'>1715</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1715'>1716</a>\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1716'>1717</a>\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1717'>1718</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1718'>1719</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1719'>1720</a>\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1720'>1721</a>\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1721'>1722</a>\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1722'>1723</a>\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1723'>1724</a>\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1724'>1725</a>\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1725'>1726</a>\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1726'>1727</a>\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1727'>1728</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1728'>1729</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1730'>1731</a>\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=1731'>1732</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py:2579\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2575'>2576</a>\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2577'>2578</a>\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2578'>2579</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2579'>2580</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2580'>2581</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2581'>2582</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2582'>2583</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2583'>2584</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2585'>2586</a>\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/generation/utils.py?line=2586'>2587</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:1818\u001b[0m, in \u001b[0;36mWhisperForConditionalGeneration.forward\u001b[0;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1812'>1813</a>\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoder_inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1813'>1814</a>\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1814'>1815</a>\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1815'>1816</a>\u001b[0m         )\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1817'>1818</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1818'>1819</a>\u001b[0m     input_features,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1819'>1820</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1820'>1821</a>\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1821'>1822</a>\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1822'>1823</a>\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1823'>1824</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1824'>1825</a>\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1825'>1826</a>\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1826'>1827</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1827'>1828</a>\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1828'>1829</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1829'>1830</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1830'>1831</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1831'>1832</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1832'>1833</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1833'>1834</a>\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_out(outputs[\u001b[39m0\u001b[39m])\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1835'>1836</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:1694\u001b[0m, in \u001b[0;36mWhisperModel.forward\u001b[0;34m(self, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1686'>1687</a>\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1687'>1688</a>\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1688'>1689</a>\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1689'>1690</a>\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1690'>1691</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1692'>1693</a>\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1693'>1694</a>\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1694'>1695</a>\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1695'>1696</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1696'>1697</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1697'>1698</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1698'>1699</a>\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1699'>1700</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1700'>1701</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1701'>1702</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1702'>1703</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1703'>1704</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1704'>1705</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1705'>1706</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1707'>1708</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1708'>1709</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:1511\u001b[0m, in \u001b[0;36mWhisperDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1497'>1498</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1498'>1499</a>\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1499'>1500</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1507'>1508</a>\u001b[0m         use_cache,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1508'>1509</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1509'>1510</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1510'>1511</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1511'>1512</a>\u001b[0m         hidden_states,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1512'>1513</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1513'>1514</a>\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1514'>1515</a>\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1515'>1516</a>\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1516'>1517</a>\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1517'>1518</a>\u001b[0m         ),\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1518'>1519</a>\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1519'>1520</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1520'>1521</a>\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1521'>1522</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1522'>1523</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=1524'>1525</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:942\u001b[0m, in \u001b[0;36mWhisperDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=939'>940</a>\u001b[0m self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=940'>941</a>\u001b[0m \u001b[39m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=941'>942</a>\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=942'>943</a>\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=943'>944</a>\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=944'>945</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=945'>946</a>\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=946'>947</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=947'>948</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=948'>949</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=949'>950</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py:791\u001b[0m, in \u001b[0;36mWhisperSdpaAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=786'>787</a>\u001b[0m \u001b[39m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=787'>788</a>\u001b[0m \u001b[39m# partitioned across GPUs when using tensor-parallelism.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=788'>789</a>\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mreshape(bsz, tgt_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim)\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=790'>791</a>\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj(attn_output)\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/transformers/models/whisper/modeling_whisper.py?line=792'>793</a>\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, \u001b[39mNone\u001b[39;00m, past_key_value\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Users/amansingh/Documents/SSR_Python/backend/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py?line=113'>114</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}